= Sharing customized models in OpenShift AI
:imagesdir: ../assets/images

++++
<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-3HTRSDJ3M4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-3HTRSDJ3M4');
</script>
++++

== Goals of this lab

Parasol is likely to create many different customized models for its business units, so effective ways to share this to different teams is important. This exercise will cover best practices for storing custom models securely and efficiently, deploying them using OpenShift AI, and verifying their functionality in a real-world environment. You will be guided through the process of saving your fine-tuned models in a way that ensures easy access and scalability, followed by detailed instructions on deploying these models within OpenShift AI. Finally, you will learn how to perform comprehensive verification checks to confirm that your models are operating as expected, ensuring they meet Parasol's high standards for reliability and performance. This hands-on session is designed to equip you with the knowledge and skills necessary to seamlessly transition from model fine-tuning to deployment and validation.

== 1. Run podman desktop

Introduction to gen AI + discover and experiment with gen AI models and AI applications on the local desktop, in an inner loop

image::rhoai/redhat-openshift-ai.png[]


== 1.1. TBD

=== 1.1.1. TBD

== 2. Start a playground, chat with it

== 3. Kill playground, try text summarization recipe, upload claim PDF, view summarization

== 4. Open summarization app (python) in vscode, inspect code (briefly)

== 5. Change the prompt, restart, and observe changes.

== Conclusion

We hope you have enjoyed this module!

Here is a quick summary of what we have learned:

- TBD
- TBD
- TBD